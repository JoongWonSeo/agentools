{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tools\n",
    "\n",
    "All about function tools with `@function_tool` decorator, `Toolkit` class and their integration with an `Assistant` classs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Turn any function into a tool\n",
    "\n",
    "You can make any function into a tool usable by the model by decorating it with `@function_tool`, but you must do the following:\n",
    "- The parameters must be type annotated\n",
    "- The return type *should* be str, but not required (currently just stringified)\n",
    "- It must be documented with a `'''docstring'''`, including each parameter (most [formats supported](https://github.com/rr-/docstring_parser), e.g. [Google-style](https://gist.github.com/redlotus/3bc387c2591e3e908c9b63b97b11d24e#file-docstrings-py-L67), [NumPy-style](https://gist.github.com/eikonomega/910512d92769b0cc382a09ae4de41771), sphinx-style, etc, see [this overview](https://gist.github.com/nipunsadvilkar/fec9d2a40f9c83ea7fd97be59261c400))\n",
    "\n",
    "You can use the tool from python as you normally would, but also the annotated tool will be auto-parsed and its JSON schema and argument validator (using pydantic) will be available as attributes on the function:\n",
    "- `tool.schema` is the (singular list of) JSON schema, which you can directly pass to the OpenAI API.\n",
    "- `tool.lookup` is a dict lookup table of the function name to the (auto-validated) function call, meaning you can just receive the model-generated function call and pass it directly to the tool.\n",
    "\n",
    "Other attributes (probably uncommon):\n",
    "- `tool.validator` is the pydantic validator, callable with kwargs to validate the arguments. This is what is saved in the lookup table.\n",
    "- `tool.tool_enabled` is a bool switch to enable/disable the tool. This is useful esp. for Toolkits, where you can dynamically enable/disable tools based on the context. Note that this only works if you wrap the tool in `ToolList` class or is part of a `Toolkit`.\n",
    "- `tool.name` should ideally not be set directly, but passed as a kwarg to `@function_tool`. It is the name of the tool, as known to the model. If not set, it will be the name of the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from types import SimpleNamespace\n",
    "import json\n",
    "import asyncio\n",
    "import logging\n",
    "import time\n",
    "\n",
    "from IPython.display import display, Markdown\n",
    "from pydantic import BaseModel\n",
    "\n",
    "from agentools import (\n",
    "    ToolList,\n",
    "    Toolkit,\n",
    "    function_tool,\n",
    "    fail_with_message,\n",
    "    call_requested_function,\n",
    "    Model,\n",
    "    Assistant, \n",
    "    MessageHistory,\n",
    "    ResponseStartEvent,\n",
    "    PartialCompletionEvent\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello from python!\n",
      "Hello from GPT!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'success'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@function_tool\n",
    "def print_to_console(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Print text to console\n",
    "\n",
    "    Args:\n",
    "        text: text to print\n",
    "    \"\"\"\n",
    "    print(text)\n",
    "    return \"success\"  # ideally, we always return something to tell the model\n",
    "\n",
    "\n",
    "# normal call\n",
    "print_to_console(\"Hello from python!\")\n",
    "\n",
    "# call from lookup table\n",
    "lookup = print_to_console.lookup\n",
    "# this would be generated by GPT\n",
    "name, arguments = \"print_to_console\", {\"text\": \"Hello from GPT!\"}\n",
    "func = lookup[name]\n",
    "func(arguments)  # notice the lack of unpacking, we pass the args dict directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello from GPT!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'success'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "call = SimpleNamespace(\n",
    "    name=\"print_to_console\", arguments=json.dumps({\"text\": \"Hello from GPT!\"})\n",
    ")\n",
    "await call_requested_function(name, json.dumps(arguments), print_to_console.lookup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid Argument: 1 validation error for print_to_console\n",
      "text\n",
      "  Input should be a valid string [type=string_type, input_value=123, input_type=int]\n",
      "Invalid Argument: 1 validation error for print_to_console\n",
      "text\n",
      "  Field required [type=missing, input_value={'content': 'Whats up?'}, input_type=dict]\n"
     ]
    }
   ],
   "source": [
    "# if the model generates an invalid argument, it is auto-validated\n",
    "print(func({\"text\": 123}))\n",
    "print(func({\"content\": \"Whats up?\"}))\n",
    "\n",
    "# notice that it's returned as string, because it should be passed to the model to correct itself"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Showing off some more goodies:\n",
    "- Even async functions should seamlessly work, just don't forget to `await` them.\n",
    "- `@fail_with_message(err)` is a decorator that will catch any exceptions thrown by the function and instead return the error message. This is useful for when you want to handle errors in a more graceful way than just crashing the model. It also takes an optional logger, which by default takes the `print` function, but any callable that takes a string will work, such as `logger.error` from the `logging` module.\n",
    "- Usually, the `@function_tool` decorator will throw an assertion error if you forget to provide the description for any of the function or their parameters. If you really don't want to provide descriptions for some (or all), maybe because it's so self-explanatory or you need to save tokens, then you can explicitly turn off the docstring parsing by passing `@function_tool(check_description=False)`. This is not recommended, but it's there if you need it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tool call fib(n=-10) failed: n must be >= 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: n must be >= 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'type': 'function',\n",
       "  'function': {'name': 'Fibonacci',\n",
       "   'description': 'Calculate the nth Fibonacci number',\n",
       "   'parameters': {'type': 'object',\n",
       "    'properties': {'n': {'description': 'The index of the Fibonacci number to calculate',\n",
       "      'type': 'integer'}},\n",
       "    'required': ['n']}}}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logger = logging.getLogger()\n",
    "\n",
    "\n",
    "@function_tool(name=\"Fibonacci\")\n",
    "@fail_with_message(\"Error\", logger=logger.error)\n",
    "async def fib(n: int):\n",
    "    \"\"\"\n",
    "    Calculate the nth Fibonacci number\n",
    "\n",
    "    Args:\n",
    "        n: The index of the Fibonacci number to calculate\n",
    "    \"\"\"\n",
    "    if n < 0:\n",
    "        raise ValueError(\"n must be >= 0\")\n",
    "\n",
    "    await asyncio.sleep(0.1)\n",
    "\n",
    "    if n < 2:\n",
    "        return n\n",
    "    return sum(await asyncio.gather(fib(n - 1), fib(n - 2)))\n",
    "\n",
    "\n",
    "print(await fib(10), flush=True)\n",
    "print(await fib.lookup[\"Fibonacci\"]({\"n\": -10}))\n",
    "fib.schema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In some situations, you might want to manually pass the JSON Schema as function argument schema instead of parsing the docstring for it. To do so, you can pass a keyword argument `json_schema` to the `@function_tool` decorator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'type': 'function',\n",
       "  'function': {'name': 'create_song',\n",
       "   'description': 'Create a song',\n",
       "   'parameters': {'type': 'object',\n",
       "    'properties': {'song': {'allOf': [{'properties': {'title': {'type': 'string'},\n",
       "         'genres': {'items': {'type': 'string'}, 'type': 'array'},\n",
       "         'duration': {'type': 'number'}},\n",
       "        'required': ['title', 'genres', 'duration'],\n",
       "        'type': 'object'}],\n",
       "      'description': 'song to add'}},\n",
       "    'required': ['song']}}}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Song(BaseModel):\n",
    "    title: str\n",
    "    genres: list[str]\n",
    "    duration: float\n",
    "\n",
    "\n",
    "@function_tool\n",
    "def create_song(song: Song):\n",
    "    \"\"\"\n",
    "    Create a song\n",
    "\n",
    "    Args:\n",
    "        song: song to add\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "\n",
    "create_song.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'type': 'function',\n",
       "  'function': {'name': 'append_song',\n",
       "   'parameters': {'type': 'object',\n",
       "    'properties': {'title': {'type': 'string'},\n",
       "     'genres': {'items': {'type': 'string'}, 'type': 'array'},\n",
       "     'duration': {'type': 'number'}},\n",
       "    'required': ['title', 'genres', 'duration']}}}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Song(BaseModel):\n",
    "    title: str\n",
    "    genres: list[str]\n",
    "    duration: float\n",
    "\n",
    "\n",
    "@function_tool(require_doc=False)\n",
    "def append_song(title: str, genres: list[str], duration: float):\n",
    "    pass\n",
    "\n",
    "\n",
    "append_song.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid Argument: 1 validation error for append_song\n",
      "duration\n",
      "  Field required [type=missing, input_value={'title': 'hi', 'genres': []}, input_type=dict]\n"
     ]
    }
   ],
   "source": [
    "print(append_song.lookup[\"append_song\"]({\"title\": \"hi\", \"genres\": []}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'type': 'function',\n",
       "  'function': {'name': 'create_song2',\n",
       "   'parameters': {'type': 'object',\n",
       "    'properties': {'title': {'type': 'string'},\n",
       "     'genres': {'items': {'type': 'string'}, 'type': 'array'},\n",
       "     'duration': {'type': 'number'}},\n",
       "    'required': ['title', 'genres', 'duration']}}}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@function_tool(json_schema=Song.model_json_schema())\n",
    "def create_song2(**song):\n",
    "    pass\n",
    "\n",
    "\n",
    "create_song2.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid Argument: 123 is not of type 'string'\n",
      "'123.5' is not of type 'number'\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    create_song2.lookup[\"create_song2\"](\n",
    "        {\"title\": \"hi\", \"genres\": [123], \"duration\": \"123.5\"}\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Toolkits: `class Toolkit`\n",
    "Toolkits are a collection of related function tools, esp. useful when they share a state. Also good for keeping the state bound to a single instance of the toolkit, rather than a global state.\n",
    "To create a toolkit, simply subclass `Toolkit` and decorate its methods with `@function_tool`.\n",
    "Enabled tools will be visible in the attributes:\n",
    "- `toolkit.schema` is the JSON schema, which you can directly pass to the OpenAI API.\n",
    "- `toolkit.lookup` is a dict lookup table of the function name to the (auto-validated) function call, meaning you can just receive the model-generated function call and pass it directly to the tool.\n",
    "\n",
    "As you noticed, the interface for OpenAI API is the same for both tools and toolkits, so you can use them interchangeably, and to use multiple tools and toolkits, simply merge their schemas and lookups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, world!\n"
     ]
    }
   ],
   "source": [
    "class Notepad(Toolkit):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.content = \"<Fill me in>\"\n",
    "\n",
    "    @function_tool\n",
    "    def write(self, text: str):\n",
    "        \"\"\"\n",
    "        Write text to the notepad\n",
    "\n",
    "        Args:\n",
    "            text: The text to write\n",
    "        \"\"\"\n",
    "        self.content = text\n",
    "\n",
    "    @function_tool(require_doc=False)\n",
    "    def read(self):\n",
    "        return self.content\n",
    "\n",
    "\n",
    "notes = Notepad()\n",
    "notes.write(\"Hello, world!\")\n",
    "print(notes.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Shhh... here's a secret: 42\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "notes.lookup[\"write\"]({\"text\": \"Shhh... here's a secret: 42\"})\n",
    "notes.lookup[\"read\"]({})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ChatGPT model and MessageHistory\n",
    "\n",
    "### ChatGPT: `class ChatGPT`\n",
    "\n",
    "Simple wrapper that keeps a message history object and optional toolkit (TODO: make into list of toolkits).\n",
    "The object is callable and simply takes a user prompt string and returns the model response string.\n",
    "\n",
    "### MessageHistory: `class MessageHistory`\n",
    "\n",
    "A simple class that keeps track of the message history, including the user and assistnat messages, along with system and tool call results. Special subclasses could be defined for things like:\n",
    "- Rolling history (e.g. last 10 messages)\n",
    "- Dynamic history based on context (e.g. vector embedding)\n",
    "- System message that constantly updates (e.g. time, weather, etc.)\n",
    "- Few-shot learning, i.e. pre-populating the history with some demonstration messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt = Assistant(\n",
    "    model=Model(\"openai\", \"gpt-3.5-turbo\"),\n",
    "    tools=ToolList(notes, print_to_console, fib),\n",
    "    messages=MessageHistory(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The text on your notepad is: \"Shhh... here's a secret: 42\"\n"
     ]
    }
   ],
   "source": [
    "response = await gpt(\"What's on my notepad?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63\n"
     ]
    }
   ],
   "source": [
    "response = await gpt(\n",
    "    \"Can you calculate the 8th fibonacci number, add it to the number in my notes, and write it? also print it to console as well.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'63'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "notes.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'user', 'content': \"What's on my notepad?\"},\n",
       " {'role': 'assistant',\n",
       "  'tool_calls': [{'id': 'call_ggtu8iEuSPdvmrywaHKlgIus',\n",
       "    'function': {'arguments': '{}', 'name': 'read'},\n",
       "    'type': 'function'}]},\n",
       " {'role': 'tool',\n",
       "  'content': \"Shhh... here's a secret: 42\",\n",
       "  'tool_call_id': 'call_ggtu8iEuSPdvmrywaHKlgIus'},\n",
       " {'content': 'The text on your notepad is: \"Shhh... here\\'s a secret: 42\"',\n",
       "  'role': 'assistant'},\n",
       " {'role': 'user',\n",
       "  'content': 'Can you calculate the 8th fibonacci number, add it to the number in my notes, and write it? also print it to console as well.'},\n",
       " {'role': 'assistant',\n",
       "  'tool_calls': [{'id': 'call_TIjTDYYzDAfkJQeNR32it2eF',\n",
       "    'function': {'arguments': '{\"n\": 8}', 'name': 'Fibonacci'},\n",
       "    'type': 'function'},\n",
       "   {'id': 'call_4OCpGoqEqVvS5fZfn3nZqyts',\n",
       "    'function': {'arguments': '{}', 'name': 'read'},\n",
       "    'type': 'function'}]},\n",
       " {'role': 'tool',\n",
       "  'content': \"Shhh... here's a secret: 42\",\n",
       "  'tool_call_id': 'call_4OCpGoqEqVvS5fZfn3nZqyts'},\n",
       " {'role': 'tool',\n",
       "  'content': '21',\n",
       "  'tool_call_id': 'call_TIjTDYYzDAfkJQeNR32it2eF'},\n",
       " {'role': 'assistant',\n",
       "  'tool_calls': [{'id': 'call_ZIF5k6asq6fIZEIGcuvzUZDA',\n",
       "    'function': {'arguments': '{\"text\":\"63\"}', 'name': 'write'},\n",
       "    'type': 'function'}]},\n",
       " {'role': 'tool',\n",
       "  'content': 'None',\n",
       "  'tool_call_id': 'call_ZIF5k6asq6fIZEIGcuvzUZDA'},\n",
       " {'role': 'assistant',\n",
       "  'tool_calls': [{'id': 'call_xLlgnJd0FjhqJgWFd7AYmFGm',\n",
       "    'function': {'arguments': '{\"text\":\"63\"}', 'name': 'print_to_console'},\n",
       "    'type': 'function'}]},\n",
       " {'role': 'tool',\n",
       "  'content': 'success',\n",
       "  'tool_call_id': 'call_xLlgnJd0FjhqJgWFd7AYmFGm'},\n",
       " {'content': 'I have calculated the 8th Fibonacci number to be 21. Adding it to the number in your notes, which is 42, gives us 63. \\n\\nI have written 63 on your notepad and printed it to the console as well.',\n",
       "  'role': 'assistant'}]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt.messages.history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Customizing our ChatGPT Class\n",
    "\n",
    "Our `Assistant` classes are based on the concept of Event Generators, i.e. a python iterator that yields different events. The above `__call__()` method is an example of an Event Handler that simply calls the event generators and reacts to the emitted events it cares about and ignores the rest. This is a very flexible design pattern that allows us to easily customize the behavior of the model.\n",
    "\n",
    "Let's override the `__call__()` method to handle some more events we care about:\n",
    "- let's print the streamed partial responses directly\n",
    "- let's use the jupyter `display` function to display the full response in a nice Markdown format\n",
    "\n",
    "Basically like the following simple toy example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "Hello, world!\n",
       "\n",
       "# How are you?\n",
       "I love earth! And everything on it!\n",
       "\n",
       "```python\n",
       "print(\"Hello, world!\")\n",
       "def fib(n):\n",
       "    if n < 0:\n",
       "         raise ValueError(\"n must be >= 0\")\n",
       "    if n < 2:\n",
       "        return n\n",
       "    return fib(n-1) + fib(n-2)\n",
       "```\n",
       "Here's a list of things I like:\n",
       "- Earth\n",
       "- The Moon\n",
       "- Mars\n",
       "- You\n",
       "- Myself\n",
       "- GPT-Wrapper\n",
       "\n",
       "Anyways, **goodbye, have a nice day**!\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def gen_response(txt):\n",
    "    for i in range(len(txt)):\n",
    "        yield txt[: i + 1]\n",
    "        time.sleep(0.01)\n",
    "\n",
    "\n",
    "t = \"\"\"\n",
    "Hello, world!\n",
    "\n",
    "# How are you?\n",
    "I love earth! And everything on it!\n",
    "\n",
    "```python\n",
    "print(\"Hello, world!\")\n",
    "def fib(n):\n",
    "    if n < 0:\n",
    "         raise ValueError(\"n must be >= 0\")\n",
    "    if n < 2:\n",
    "        return n\n",
    "    return fib(n-1) + fib(n-2)\n",
    "```\n",
    "Here's a list of things I like:\n",
    "- Earth\n",
    "- The Moon\n",
    "- Mars\n",
    "- You\n",
    "- Myself\n",
    "- GPT-Wrapper\n",
    "\n",
    "Anyways, **goodbye, have a nice day**!\n",
    "\"\"\"\n",
    "\n",
    "for r in gen_response(t):\n",
    "    display(Markdown(r), clear=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NotebookGPT(Assistant):\n",
    "    async def __call__(self, prompt: str, **kwargs):\n",
    "        output = \"\"\n",
    "        async for event in self.response_events(prompt, **kwargs):\n",
    "            match event:\n",
    "                case ResponseStartEvent():\n",
    "                    output += f\"**[USER]:** {event.prompt}\\n\\n**[GPT]:** \"\n",
    "                    display(Markdown(output), clear=True)\n",
    "\n",
    "                case PartialCompletionEvent(chunk, partial, call_index):\n",
    "                    try:\n",
    "                        if d := chunk.choices[0].delta.content:\n",
    "                            output += d\n",
    "                            display(Markdown(output), clear=True)\n",
    "                    except:\n",
    "                        pass\n",
    "\n",
    "\n",
    "gpt = NotebookGPT(MessageHistory([]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**[USER]:** Hey! How are you?\n",
       "\n",
       "**[GPT]:** "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "await gpt(\"Hey! How are you?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**[USER]:** Can you give me a python implementation of the fibonacci sequence iteratively?\n",
       "\n",
       "**[GPT]:** "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "await gpt(\n",
    "    \"Can you give me a python implementation of the fibonacci sequence iteratively?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Even more customization\n",
    "\n",
    "So far we've only overriden the Event Handlers, with which you can go pretty far. However, you can also override the Event Generators to customize the behavior even more. You could define new Events and then yield them in your custom overriden Event Generators.\n",
    "\n",
    "This could be useful when you're looking into advanced use cases, such as Code Interpreter with a \"hacked\" python tool, in order to get around the issue of all tool arguments being in JSON format, and the model often makes syntax mistakes in writing long blocks of code while simultaneously encoding it in a JSON string format (escaping new lines and quotes, etc.). For this, you would override the tool text message content handler (currently a TODO).\n",
    "\n",
    "Another example could be for human-in-the-loop tools, e.g. you want the user to explictly confirm the tool call before it's actually executed for critical tools. For this you could yield a new Event called `ConfirmToolCall` and then override the `tool_events` generator to yield this event when needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note from ferdy: the last few cells are not working as you expected (also doesn't work in the original agentools), because the event is not PartialCompletionEvent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
